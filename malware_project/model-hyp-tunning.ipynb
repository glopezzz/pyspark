{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4679bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\hyperopt\\atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from hyperopt import hp, fmin, Trials, tpe, STATUS_OK\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464db8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as file:\n",
    "    conf = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079c61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName('iot')\n",
    "    .master('local[*]')\n",
    "    .config('spark.driver.host', 'localhost')\n",
    "    .config('spark.driver.bindAddress', '127.0.0.1')\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbd189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading previuos df and model\n",
    "df_train = spark.read.parquet(conf['filepath_train_df'])\n",
    "df_test = spark.read.parquet(conf['filepath_test_df'])\n",
    "loaded_pipeline = Pipeline.load('./pipeline')\n",
    "string_indexer = loaded_pipeline.getStages()[0]\n",
    "vector_assembler = loaded_pipeline.getStages()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80834824",
   "metadata": {},
   "source": [
    "## Hyper Opt\n",
    " Optimization library that allows for a range of values instead of discrete values like GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cd0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='is_bad', metricName=\"areaUnderROC\")\n",
    "\n",
    "def objective(params):\n",
    "    rf = RandomForestClassifier(\n",
    "        featuresCol = 'features',\n",
    "        labelCol = 'is_bad',\n",
    "        numTrees = params['numTrees'],\n",
    "        maxDepth = params['maxDepth'],\n",
    "    )\n",
    "    \n",
    "    inter_pipeline = Pipeline(\n",
    "        stages=[\n",
    "            string_indexer,\n",
    "            vector_assembler,\n",
    "            rf\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = inter_pipeline.fit(df_train)\n",
    "    val_df = pipeline.transform(df_test)\n",
    "        \n",
    "    score = evaluator.evaluate(val_df)\n",
    "    return {\"loss\":-score, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13332c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:15<00:00, 85.13s/trial, best loss: -0.9999983774583976] \n",
      "Final numTrees:  108.0\n",
      "Final maxDepth:  10.0\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'numTrees' : hp.uniformint('numTrees', 10, 500),\n",
    "    'maxDepth' : hp.uniformint('maxDepth', 2, 10)\n",
    "}\n",
    "\n",
    "rf_trials = Trials()\n",
    "\n",
    "argmin = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 3,\n",
    "    trials = rf_trials\n",
    ")\n",
    "print('Final numTrees: ',argmin['numTrees'])\n",
    "print('Final maxDepth: ',argmin['maxDepth'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c22f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new optimized Pipeline\n",
    "best_rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"is_bad\",\n",
    "    numTrees=argmin['numTrees'],\n",
    "    maxDepth=argmin['maxDepth']\n",
    ")\n",
    "\n",
    "best_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        string_indexer,\n",
    "        vector_assembler,\n",
    "        best_rf\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f84d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to the new Pipeline\n",
    "best_pl_fit = best_pipeline.fit(df_train)\n",
    "test_preds = best_pl_fit.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68692b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 0.9999983770988485\n"
     ]
    }
   ],
   "source": [
    "# Evaluate new Pipeline\n",
    "score = evaluator.evaluate(test_preds)\n",
    "print(\"ROC AUC\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e411fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.write().overwrite().save(\"pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
